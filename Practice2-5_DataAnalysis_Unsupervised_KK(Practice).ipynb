{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34b0abba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel64 Family 6 Model 154 Stepping 3, GenuineIntel\n",
      "16(GB)\n",
      "Windows\n",
      "10.0.22621\n",
      "C:\\DataScience\\Lecture\\All-About-Machine-Learning\\Test\n",
      "2023-01-04 12:28:59.787240\n",
      "2023-03-15 14:35:31.287414\n",
      "2023-03-15 14:35:31.287414\n",
      "2023-03-15 14:35:49.645813\n",
      "다음 출력을 파일명으로 설정하고 제출하시오: 김경원_20211011_인공지능활용디지털경제플랫폼연구_DA_Unsupervised\n"
     ]
    }
   ],
   "source": [
    "### 시작 및 본인정보 반영\n",
    "# 반드시 이 cell을 실행하시오\n",
    "# 실행하지 않을 시 직접 하지 않은 것으로 간주\n",
    "# 마지막 줄 출력으로 파일명을 설정하고 제출 필수\n",
    "import platform, psutil, os, datetime\n",
    "print(platform.processor())\n",
    "print(str(round(psutil.virtual_memory().total / (1024.0 **3)))+\"(GB)\")\n",
    "print(platform.system())\n",
    "print(platform.version())\n",
    "print(os.getcwd())\n",
    "print(datetime.datetime.fromtimestamp(os.path.getctime(os.getcwd())))\n",
    "print(datetime.datetime.fromtimestamp(os.path.getmtime(os.getcwd())))\n",
    "print(datetime.datetime.fromtimestamp(os.path.getatime(os.getcwd())))\n",
    "print(datetime.datetime.now())\n",
    "title = 'DA_Unsupervised'    # 고정값\n",
    "name = '김경원'    # 본인 이름을 작성\n",
    "studentid = '20211011'    # 본인 학번을 작성\n",
    "# 아래 강좌 명 중 본인이 수강하는 강과명 작성\n",
    "# 비즈니스데이터사이언스이해, E정보시스템, 디지털비즈니스애널리틱스, E데이터베이스, 인공지능기반의사결정, 빅데이터 등\n",
    "# 비즈니스혁신을위한데이터사이언스응용, 인공지능활용디지털경제플랫폼연구 등\n",
    "course = '인공지능활용디지털경제플랫폼연구'    \n",
    "print('다음 출력을 파일명으로 설정하고 제출하시오:', name + '_' + studentid + '_' + course + '_' + title)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11d78dd",
   "metadata": {},
   "source": [
    "# **Data Loading:** 분석에 사용할 데이터 불러오기\n",
    "\n",
    "- 아래 `비즈니스 문제 대상 데이터`의 비즈니스 목적을 보고 `관심있는 데이터`를 선택하여 불러오기\n",
    "- 모든 데이터는 [Kaggle Competition](https://www.kaggle.com/)에서 추출되었으며, `현 Jupyter Notebook`과 동일폴더에 있음\n",
    "- 저장된 데이터는 아래 설명 참고링크에서 다움받은 후 `일부 전처리 후 저장`되어 있기 떄문에 다를 수 있고 `저장된 데이터만 사용`\n",
    "- 개인PC에서 `pandas -> read_csv()`로 불러오기 가능하고 `Google Colab으로 로딩`도 불러와도 됨\n",
    "- 모든 데이터 분석 결과들은 향후 `경진대회나 공모전 및 데이터사이언스 분야 면접이나 시험`에 대비 가능\n",
    "\n",
    "| **분야** | **비즈니스 목적** | **파일명** | **종속변수 Y** | **설명 참고링크** |\n",
    "|:---:|:---|:---|:---|:---|\n",
    "| **Tour** | 고객들의 여행취소를 정확하게 예측하여   취소가 예상되는 고객을 찾고 기업의 매출손실 대비 | `Classification_TravelCustomerChurn.csv` | `Target` | https://www.kaggle.com/datasets/tejashvi14/tour-travels-customer-churn-prediction |\n",
    "| **Marketing** | 마케팅이 구매로 이어지는 관계를   정확하게 예측 및 특성을 확인하여 마케팅 효과를 높이고 매출 향상 지원 | `Classification_MarketingEfficiency.csv` | `Response` | https://www.kaggle.com/datasets/rodsaldanha/arketing-campaign |\n",
    "| **Human** | 기업 임직원들의 불만족을 정확하게   예측하여 퇴사 확률을 낮출 수 있는 인사전략 지원 | `Classification_JobSatisfaction.csv` | `satisfaction_level` | https://www.kaggle.com/datasets/mfaisalqureshi/hr-analytics-and-job-prediction |\n",
    "| **Medicine** | 심장질환 여부를 정확하게 예측하여   심장질환에 걸릴 가능성이 높은 고객의 특징을 예측 | `Classification_HeartDisease.csv` | `TenYearCHD` | https://www.kaggle.com/datasets/dileep070/heart-disease-prediction-using-logistic-regression |\n",
    "| **Ecommerce** | 이커머스 만족도를 정확하게 예측하여   만족도 향상을 위한 특성을 확인하고 고객 유입 전략 지원 | `Classification_EcommerceSatisfaction.csv` | `Customer_rating` | https://www.kaggle.com/datasets/prachi13/customer-analytics |\n",
    "| **Service** | 항공기를 이용하는 고객의 서비스   만족도를 정확하게 예측하여 특성을 확인하고 추가적인 서비스기획 지원 | `Classification_AirlineSatisfaction.csv` | `satisfaction` | https://www.kaggle.com/datasets/sjleshrac/airlines-customer-satisfaction |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b713a06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ee9733",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0807b4e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a223fe5d",
   "metadata": {},
   "source": [
    "# **Data Analysis Summary:** 기존 문제 해결 결과 정리\n",
    "\n",
    "**1)** 기존 `분류문제 해결`과제의 `데이터분석 과정의 모든 코드를 실행`\n",
    "\n",
    "> - 분류문제의 경우, `Practice2-3_DataAnalysis_SupervisedClassification_KK(Practice)` 파일의 분석결과 코드 정리\n",
    "> - `Data Loading + Import Library + Preprocessing + Applying Base Algorithm + Evaluation` 단계를 하나의 셀에 모두 실행하여 성능 출력\n",
    "\n",
    "**2)** 기존 `Business Insight and Application` 단계에서의 데이터분석결과 기반 비즈니스 기획 및 전략 `주석으로 작성`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dcec709",
   "metadata": {},
   "source": [
    "## (1) 기존 `분류문제 해결`과제의 `데이터분석 과정의 모든 코드를 실행`\n",
    "\n",
    "> - 분류문제의 경우, `Practice2-3_DataAnalysis_SupervisedClassification_KK(Practice)` 파일의 분석결과 코드 정리\n",
    "> - `Data Loading + Import Library + Preprocessing + Applying Base Algorithm + Evaluation` 단계를 하나의 셀에 모두 실행하여 성능 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b38b33e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d45cf3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "635a0cbf",
   "metadata": {},
   "source": [
    "## (2) 기존 `Business Insight and Application` 단계에서의 데이터분석결과 기반 비즈니스 기획 및 전략 `주석으로 작성`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699c2d1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035f3cec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "feb20686",
   "metadata": {},
   "source": [
    "# **Performance Update**\n",
    "\n",
    "<center><img src='Image/Advanced/Unsupervised_Clustering_Reduction.png' width='900'></center>\n",
    "\n",
    "## Clustering\n",
    "\n",
    "**1)** 군집화의 대표적인 알고리즘인 `비지도학습(Unsupervised) 방법론인 K-means 알고리즘`을 사용하여 `예측 성능 확인`\n",
    "\n",
    "> - 데이터는 위에 정리된 `기존 문제해결 과정에서 변환 및 전처리 된 데이터를 그대로 사용`\n",
    ">> - 사용데이터 변수명: `X_train, Y_train, X_test, Y_test`\n",
    "> - 모델링에서 사용하는 `클러스터의 갯수는 종속변수의 unique value 갯수`로 반영\n",
    "> - Train & Test 모두에서 `실제 종속변수` 라벨 별 `샘플 갯수 Table` 출력\n",
    "> - Train & Test 모두에서 `예측 종속변수`에 대한 `Confusion Matrix` 출력\n",
    "> - Train & Test 모두에서 예측 성능 확인을 위해 `실루엣 점수, ARI, AMI` 출력\n",
    "> - Test에서 클러스터의 갯수를 `2개부터 5개까지 증가`시키면서 `실루엣 점수, ARI, AMI` 각 평가지표의 변화를 `시각화`\n",
    "\n",
    "**2)** `Downsampling`을 사용하여 `예측 성능 확인`\n",
    "\n",
    "> - Train & Test 모두에서 `실제 종속변수` 라벨 별 `샘플 갯수 Table` 출력\n",
    "> - Train 데이터에서 종속변수의 라벨 별 샘플의 수 중, `샘플 수가 많은 라벨의 샘플 갯수를 적은 라벨의 샘플 갯수만큼 인위적으로 줄임(Downsampling 정의)`\n",
    "> - Test 데이터는 다운샘플링 하지 않고 이전 과정에서 전처리된 것을 그대로 사용하며, `모델링에서 데이터 학습에 사용되는 Train만 다운샘플링`\n",
    ">> - ex) 0의 갯수는 500개 + 1의 갯수는 100개 $\\rightarrow$ 0의 갯수는 100개 + 1의 갯수는 100개\n",
    ">> - 샘플을 줄일 때는 head/tail 등의 함수로 100개를 선택하는것이 아니라 `반드시 random 하게 100개를 선택`\n",
    ">> - 샘플을 줄일 때 사용하는 함수는 `정해진 방식 없이 자유롭게 사용` 가능\n",
    ">> - 사용데이터 변수명: `X_train_down, Y_train_down, X_test, Y_test`\n",
    "> - 모델링에서 사용하는 `클러스터의 갯수는 종속변수의 unique value 갯수`로 반영\n",
    "> - Train & Test 모두에서 `실제 종속변수` 라벨 별 `샘플 갯수 Table` 재출력하여 변화를 확인\n",
    "> - Train & Test 모두에서 `예측 종속변수`에 대한 `Confusion Matrix` 출력\n",
    "> - Train & Test 모두에서 예측 성능 확인을 위해 `실루엣 점수, ARI, AMI` 출력\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44107d4",
   "metadata": {},
   "source": [
    "### (1) 군집화의 대표적인 알고리즘인 `비지도학습(Unsupervised) 방법론인 K-means 알고리즘`을 사용하여 `예측 성능 확인`\n",
    "\n",
    "> - 데이터는 위에 정리된 `기존 문제해결 과정에서 변환 및 전처리 된 데이터를 그대로 사용`\n",
    ">> - 사용데이터 변수명: `X_train, Y_train, X_test, Y_test`\n",
    "> - 모델링에서 사용하는 `클러스터의 갯수는 종속변수의 unique value 갯수`로 반영\n",
    "> - Train & Test 모두에서 `실제 종속변수` 라벨 별 `샘플 갯수 Table` 출력\n",
    "> - Train & Test 모두에서 `예측 종속변수`에 대한 `Confusion Matrix` 출력\n",
    "> - Train & Test 모두에서 예측 성능 확인을 위해 `실루엣 점수, ARI, AMI` 출력\n",
    "> - Test에서 클러스터의 갯수를 `2개부터 5개까지 증가`시키면서 `실루엣 점수, ARI, AMI` 각 평가지표의 변화를 `시각화`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed63c6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc7b65d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4db84336",
   "metadata": {},
   "source": [
    "### (2) 군집화의 대표적인 알고리즘인 `비지도학습(Unsupervised) 방법론인 K-means 알고리즘`을 사용하여 `예측 성능 확인`\n",
    "\n",
    "> - 데이터는 위에 정리된 `기존 문제해결 과정에서 변환 및 전처리 된 데이터를 그대로 사용`\n",
    ">> - 사용데이터 변수명: `X_train, Y_train, X_test, Y_test`\n",
    "> - 모델링에서 사용하는 `클러스터의 갯수는 종속변수의 unique value 갯수`로 반영\n",
    "> - Train & Test 모두에서 `실제 종속변수` 라벨 별 `샘플 갯수 Table` 출력\n",
    "> - Train & Test 모두에서 `예측 종속변수`에 대한 `Confusion Matrix` 출력\n",
    "> - Train & Test 모두에서 예측 성능 확인을 위해 `실루엣 점수, ARI, AMI` 출력\n",
    "> - Test에서 클러스터의 갯수를 `2개부터 5개까지 증가`시키면서 `실루엣 점수, ARI, AMI` 각 평가지표의 변화를 `시각화`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c452e80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4792e086",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "74e98b0f",
   "metadata": {},
   "source": [
    "## Reduction\n",
    "\n",
    "**3-1)** 차원축소의 대표적인 알고리즘인 `비지도학습(Unsupervised) 방법론인 PCA 알고리즘`을 사용하여 `데이터를 전처리`\n",
    "\n",
    "> - 데이터는 위 `Downsampling 과정에서 전처리된 Train`과 `원래의 Test 데이터를 그대로 사용`\n",
    "> - PCA 알고리즘으로 Train을 학습한 후 `새로운 차원/갯수의 독립변수 Train & Test 데이터 생성`\n",
    ">> - 사용데이터 변수명: `X_train_pca, Y_train_down, X_test_pca, Y_test`\n",
    "> - `새롭게 생성된 독립변수들의 의미`와 알고리즘 반영 비율을 확인하기 위해,\n",
    ">> - Train 데이터 기준, `추정된 고유벡터를 시각화`하여 `독립변수와의 상관성을 기준으로 고유벡터의 의미 주석으로 작성`\n",
    ">> - `Scree Plot`으로 각 `고유벡터의 분산 설명 비율과 누적값 2가지를 시각화`\n",
    ">> - 약 80% 이상의 분산설명비율을 기준으로, `몇개의 독립변수를 선택해야 하는지 주석으로 설명하고 새로운 차원/갯수의 독립변수 Train & Test 데이터`로 확정\n",
    ">> - `Scaling`도 반드시 실행하되 `이전 전처리 또는 분석과정에서 사용한 방법론을 그대로 사용`\n",
    "\n",
    "**3-2)** `비지도학습(Unsupervised) 방법론인 K-means 알고리즘`을 사용하여 `예측 성능 확인`\n",
    "\n",
    "> - Test에서 예측 성능 확인을 위해 `Confucion Matrix, 실루엣 점수, ARI, AMI` 출력\n",
    "> - `분산설명비율을 85%, 90%. 95% 및 100%`로 증가시키면서 새로운 독립변수의 수를 증가시키면서 Test 데이터의 `Confucion Matrix, 실루엣 점수, ARI, AMI` 출력 또는 시각화\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9e7a10",
   "metadata": {},
   "source": [
    "### (1) 차원축소의 대표적인 알고리즘인 `비지도학습(Unsupervised) 방법론인 PCA 알고리즘`을 사용하여 `데이터를 전처리`\n",
    "\n",
    "> - 데이터는 위 `Downsampling 과정에서 전처리된 Train`과 `원래의 Test 데이터를 그대로 사용`\n",
    "> - PCA 알고리즘으로 Train을 학습한 후 `새로운 차원/갯수의 독립변수 Train & Test 데이터 생성`\n",
    ">> - 사용데이터 변수명: `X_train_pca, Y_train_down, X_test_pca, Y_test`\n",
    "> - `새롭게 생성된 독립변수들의 의미`와 알고리즘 반영 비율을 확인하기 위해,\n",
    ">> - Train 데이터 기준, `추정된 고유벡터를 시각화`하여 `독립변수와의 상관성을 기준으로 고유벡터의 의미 주석으로 작성`\n",
    ">> - `Scree Plot`으로 각 `고유벡터의 분산 설명 비율과 누적값 2가지를 시각화`\n",
    ">> - 약 80% 이상의 분산설명비율을 기준으로, `몇개의 독립변수를 선택해야 하는지 주석으로 설명하고 새로운 차원/갯수의 독립변수 Train & Test 데이터`로 확정\n",
    ">> - `Scaling`도 반드시 실행하되 `이전 전처리 또는 분석과정에서 사용한 방법론을 그대로 사용`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dcf1de1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfbf5de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7ec324c6",
   "metadata": {},
   "source": [
    "### (2) `비지도학습(Unsupervised) 방법론인 K-means 알고리즘`을 사용하여 `예측 성능 확인`\n",
    "\n",
    "> - Test에서 예측 성능 확인을 위해 `Confucion Matrix, 실루엣 점수, ARI, AMI` 출력\n",
    "> - `분산설명비율을 85%, 90%. 95% 및 100%`로 증가시키면서 새로운 독립변수의 수를 증가시키면서 Test 데이터의 `Confucion Matrix, 실루엣 점수, ARI, AMI` 출력 또는 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a848b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8503a259",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "911c2eb0",
   "metadata": {},
   "source": [
    "## Other Approaches\n",
    "\n",
    "**4)** 추가적인 예측 성능을 향상 시키기 위한 방법를 `조사 및 창의적으로 개발하여 자유롭게 적용`\n",
    "\n",
    "- 이전 과정들을 포함하여 `예측 성능은 좋아질 수도 안좋아질 수도 있음`\n",
    "- 동일한 문제와 데이터를 분석하더라도 `데이터분석가에 따라 성능은 달라질 수 있음`\n",
    "- 앞선 과정들을 포함하여 기존에 존재하는 해결방법들은 `경쟁사들도 모두 사용하는 방식`이기 때문에 `미래에는 효과가 없음`\n",
    "- 따라서 실제 현실 비즈니스에서는 여러분들이 배우지 않은 `새로운 방법을 찾고 창의적으로 개발하여 적용`해야 함\n",
    "- 그러한 과정을 한번쯤 경험해 보기를.. \n",
    "- `책은 지나간 과거라서 그저 참고만 될 뿐, 미래는 어떤 책에서도 항상 정답이 없고..`\n",
    "- `따라서 여러분 인생에서 이 시험의 정답은 미래에 전혀 가치가 없고 쓸모도 없을 뿐더러..`\n",
    "- `오로지 미래에도 쓸수 있는 것은 어떤 백지에서도 (1) 빠르고 정확하게 (2) 선착순으로 (3) 문제를 해결하는 역량뿐!`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961a5942",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cac7aaf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22842959",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "954ee93b",
   "metadata": {},
   "source": [
    "# **Best Model Summary:** 가장 예측 성능이 좋은 모델링 결과 정리\n",
    "\n",
    "\n",
    "**1)** 위 4가지 분석 과정 중 가장 예측 성능이 좋았던 데이터분석 결과를 정리\n",
    "\n",
    "> - 4가지 분석 과정에서 성능이 좋아질수도 나빠졌을 수도 있는데 `그 이유에 대해서 자유롭게 주석으로 작성`\n",
    "> - 가장 성능 좋은 `데이터분석과 과정의 전처리부터 모델링 및 평가까지의 흐름을 주석으로 정리하여 설명`\n",
    "> - 가장 성능 좋은 모델링 기준, Train & Test에서 `Classification Report, ROC Curve, AUC`를 추가적으로 출력\n",
    "> - 전체 모델링 과정에서 `불러온 데이터를 입력받아` Train & Test의 `Classification Report, ROC Curve, AUC`를 출력하는 `Best_Model`이라는 함수명으로 구현하여 `실제 입출력이 잘 실행되는지 결과 출력` \n",
    "\n",
    "**2)** 분석결과의 `비즈니스 활용 기획 및 전략`\n",
    "\n",
    "> - `기존 문제 해결 결과 정리` 단계에서의 비즈니스 활용 기획 및 전략이 `가장 성능이 좋은 모델링 기준 (변경이 필요하다면)어떻게 변경되어야 하는지 주석으로 작성`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48de7413",
   "metadata": {},
   "source": [
    "## (1) 위 4가지 분석 과정 중 가장 예측 성능이 좋았던 데이터분석 결과를 정리\n",
    "\n",
    "> - 4가지 분석 과정에서 성능이 좋아질수도 나빠졌을 수도 있는데 `그 이유에 대해서 자유롭게 주석으로 작성`\n",
    "> - 가장 성능 좋은 `데이터분석과 과정의 전처리부터 모델링 및 평가까지의 흐름을 주석으로 정리하여 설명`\n",
    "> - 가장 성능 좋은 모델링 기준, Train & Test에서 `Classification Report, ROC Curve, AUC`를 추가적으로 출력\n",
    "> - 전체 모델링 과정에서 `불러온 데이터를 입력받아` Train & Test의 `Classification Report, ROC Curve, AUC`를 출력하는 `Best_Model`이라는 함수명으로 구현하여 `실제 입출력이 잘 실행되는지 결과 출력` \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d264cc44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61eba0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "36386859",
   "metadata": {},
   "source": [
    "## (2) 분석결과의 `비즈니스 활용 기획 및 전략`\n",
    "\n",
    "> - `기존 문제 해결 결과 정리` 단계에서의 비즈니스 활용 기획 및 전략이 `가장 성능이 좋은 모델링 기준 (변경이 필요하다면)어떻게 변경되어야 하는지 주석으로 작성`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0334fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6afcd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062396f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0452fd47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel64 Family 6 Model 154 Stepping 3, GenuineIntel\n",
      "16(GB)\n",
      "Windows\n",
      "10.0.22621\n",
      "C:\\DataScience\\Lecture\\All-About-Machine-Learning\\Test\n",
      "2023-01-04 12:28:59.787240\n",
      "2023-03-15 14:35:50.203313\n",
      "2023-03-15 14:35:50.203313\n",
      "2023-03-15 14:35:55.963914\n",
      "다음 출력을 파일명으로 설정하고 제출하시오: 김경원_20211011_인공지능활용디지털경제플랫폼연구_DA_Unsupervised\n"
     ]
    }
   ],
   "source": [
    "### 종료 및 본인정보 반영\n",
    "# 반드시 이 cell을 실행하시오\n",
    "# 실행하지 않을 시 직접 하지 않은 것으로 간주\n",
    "# 마지막 줄 출력으로 파일명을 설정하고 제출 필수\n",
    "import platform, psutil, os, datetime\n",
    "print(platform.processor())\n",
    "print(str(round(psutil.virtual_memory().total / (1024.0 **3)))+\"(GB)\")\n",
    "print(platform.system())\n",
    "print(platform.version())\n",
    "print(os.getcwd())\n",
    "print(datetime.datetime.fromtimestamp(os.path.getctime(os.getcwd())))\n",
    "print(datetime.datetime.fromtimestamp(os.path.getmtime(os.getcwd())))\n",
    "print(datetime.datetime.fromtimestamp(os.path.getatime(os.getcwd())))\n",
    "print(datetime.datetime.now())\n",
    "title = 'DA_Unsupervised'    # 고정값\n",
    "name = '김경원'    # 본인 이름을 작성\n",
    "studentid = '20211011'    # 본인 학번을 작성\n",
    "# 아래 강좌 명 중 본인이 수강하는 강과명 작성\n",
    "# 비즈니스데이터사이언스이해, E정보시스템, 디지털비즈니스애널리틱스, E데이터베이스, 인공지능기반의사결정, 빅데이터 등\n",
    "# 비즈니스혁신을위한데이터사이언스응용, 인공지능활용디지털경제플랫폼연구 등\n",
    "course = '인공지능활용디지털경제플랫폼연구'    \n",
    "print('다음 출력을 파일명으로 설정하고 제출하시오:', name + '_' + studentid + '_' + course + '_' + title)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "307.198px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
